<h1>Hand Gesture Recognition</h1>

With the advancement of computer vision, we are able to harness the ability to communicate with machines to recognise our gestures in order to trigger an action or to signal communication. As of now, my project can predict gestures and display it on the screen.

<h2>Introduction</h2>
This project uses Google's MediaPipe, an open-source framework, to detect hand landmarks in real-time. By integrating machine learning, the application recognizes hand gestures and maps them to specific actions. Additionally, OpenCV is used to process images and video streams efficiently, providing an interactive interface.

<h2>Modules/Libraries used</h2>
- Numpy -> Used for complex mathematical computations and array handling. <br>
- OpenCV -> Image/Video processing. <br>
- MediaPipe -> Live hand landmark detection and tracking. <br>
- PIL -> Primarily used for image processing. <br>
- Keras -> Used for loading and utilisation of pretrained models. <br>
